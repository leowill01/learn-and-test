---
title: "Learn: package `GenomicDataCommons`"
author: "Leo Williams"
params:
  GDC_TOKEN_FILE: "/Users/leo/Downloads/gdc-user-token.2019-11-26T21_38_34.897Z.txt"
---

# About

This tutorial is adapted from the instructional document [***The `GenomicDataCommons` Package***](https://bioconductor.org/packages/release/bioc/vignettes/GenomicDataCommons/inst/doc/overview.html#1_what_is_the_gdc).

# Setup

```{r setup, results='hide'}
library(GenomicDataCommons)
library(ggplot2)

# Set params
Sys.setenv(GDC_TOKEN_FILE = params$GDC_TOKEN_FILE) # Needs to be an environment variable to be read by gdc_token()
```

# 1 What is the GDC?

# 2 Quickstart

## 2.1 Installation

## 2.2 Check connectivity and status

Check required network activity:

```{r}
status()
```

Check status in code:

```{r}
stopifnot(status()$status == "OK")
```

## 2.3 Find data [complete later]

## 2.4 Download data

## 2.5 Metadata queries

# 3 Basic design

This package design is meant to have some similarities to the “hadleyverse” approach of dplyr. Roughly, the functionality for finding and accessing files and metadata can be divided into:

1. Simple query constructors based on GDC API endpoints.
2. A set of verbs that when applied, adjust filtering, field selection, and faceting (fields for aggregation) and result in a new query object (an endomorphism)
3. A set of verbs that take a query and return results from the GDC

Here is an overview of functionality:

- Creating a query:
	- `projects()`
	- `cases()`
	- `files()`
	- `annotations()`
- Manipulating a query:
	- `filter()`
	- `facet()`
	- `select()`
- Introspection on the GDC API fields:
	- `mapping()`
	- `available_fields()`
	- `default_fields()`
	- `grep_fields()`
	- `field_picker()`
	- `available_values()`
	- `available_expand()`
- Executing an API call to retrieve query results
	- `results()`
	- `count()`
	- `response()`
- Raw data file downloads
	- `gdcdata()`
	- `transfer()`
	- `gdc_client()`
- Summarizing and aggregating field values (faceting)
	- `aggregations()`
- Authentication
	- `gdc_token()`
- BAM file slicing
	- `slicing()`
	
# 4 Usage

Two main classes of operations when working with the GDC:

1. Querying metadata and finding data files
2. Transferring raw or processed data

## 4.1 Querying metadata

Typically, one wants to query metadata to either filter to find files to download *or* to perform an aggregation (e.g. similar to `table()`).

General steps for querying metadata:

1. Create a "blank" query
2. `filter` to limit results
3. Retrieve results 

The `GenomicDataCommons` has helper functions to for listing fields that are available for filtering.

In addition to fetching results, the GDC API allows faceting/aggregating, which is useful for making reports, dashboards, etc.

### 4.1.1 Creating a query

Queries start in R and follow the four metadata ***endpoints*** available at the GDC (i.e. your query should be what you eventually want to retrieve, e.g. if you want to input case IDs and retrieve Varscan2 variant files, use a `files()` query):

- `projects()`
- `cases()`
- `files()`
- `annotations()`

Make an object of class `GDCQuery` (also has class `gdc_projects` and `list`)

```{r}
pquery = projects()
pquery
```

The object has the following elements:

- `$fields`: char vector of the fields to be returned when the data is retrieved. The default fields will be used (`default_fields()`) if no fields are specified.
- `$filters`: contains results after calling the `filter()` method and is used to filter results upon retrieval
- `$facets`: char vector of field names used to aggregate data with `aggregations()`
- `$archive`: either "default" or "legacy"
- `$token`: character token from the GDC. See the authentication section for details.

Look at the structure of the query

```{r}
class(pquery)
str(pquery)
```

### 4.1.2 Retrieving results

With a query object, we can retrieve information from the GDC. The most basic type of results is a simple `count()` of records that satisfy the filter criteria.

***Note***: We haven't set any filters so a `count()` here will represent all the project records publicly available in the GDC "default" archive.

```{r}
pcount = count(pquery)
# or
pcount = pquery %>% count()
pcount
```

The `results()` method will fetch actual results:

```{r}
presults = pquery %>% results()
str(presults)
```

A default of only 10 records are returned. You can use `size` and `from` arguments to `results()` to either page through results or to change the number of results. `results_all()` will simply fetch all the available results given a query. ***NOTE***: this may take a long time and return a ***huge*** results set if not used carefully. Use a combination of `counts()` and `results()` to estimate data size before using `results_all()`.

```{r}
length(ids(presults))
```

```{r}
presults = pquery %>% results_all()
length(ids(presults))
```

```{r}
# includes all records
length(ids(presults)) == count(pquery)
```

### 4.1.3 Fields and values

Central to querying and retrieving data is the ability to specify which fields to return, filtering by fields and values, and faceting or aggregating. The `GenomicDataCommons` package has two simple functions, `available_fields()` and `default_fields()`. Each can operate on a character endpoint name ("cases", "files", "annotations", or "projects") or a `GDCQuery` object

```{r}
default_fields("files")
```

The number of fields ***available*** for the "files" endpoint:

```{r}
length(available_fields("files"))
```

The first few fields available for the "files" endpoint:

```{r}
head(available_fields("files"))
```

The fields returned by a query can be specified following a similar paradigm to that of the `dplyr` package. The `select()` function is a verb that resets the fields slot of a `GDCQuery`. ***NOTE*** that this is not quite analagous to the dplyr `select()` verb that limits from already-present fields. We *completely* replace the fields when using `select()` on a `GDCQuery`.

```{r}
# default fields here
qcases = cases()
qcases$fields
```

Set up query to use *all* available fields. ***Note*** that checking of fields is done by `select()`.

```{r}
qcases = cases() %>% GenomicDataCommons::select(available_fields("cases"))
head(qcases$fields)
```

### 4.1.4 Facets and aggregation

GDC API aggregation feature: specify one or more fields (of appropriate type) and return a count of the number of records matching each potential value (similar to the R `table()` function). Multiple fields can be returned at once, but the GDC API foes not have a cross-tabulation feature - all aggregations are only on one field at a time. 

Results of `aggregation()` calls come back as a list of tibbles.

```{r}
# total number of files of a specific type
res = files() %>% 
	facet(c("type", "data_type")) %>% # names of fields to facet by
	aggregations()
res$type
res$data_type
```

`aggregations()` is an easy way to learn the contents of individual fields and forms the basis for faceted search pages.

### 4.1.5 Filtering

The GenomicDataCommons package uses a form of non-standard evaluation to specify R-like queries that are then translated into an R list. That R list is, upon calling a method that fetches results from the GDC API, translated into the appropriate JSON string. The R expression uses the formula interface as suggested by Hadley Wickham in his [vignette on non-standard evaluation](http://adv-r.had.co.nz/Computing-on-the-language.html).

```{r}
# count all projects in the GDC
qprojects = projects() 
qprojects %>% count()

# count all cases in the GDC
qcases = cases() 
qcases %>% count()

# count all files in the GDC
qfiles = files()
qfiles %>% count()
```

To limit the file type, we can refer back to the section on faceting to see the possible values for the field "type". For example, to filter file results to only "gene_expression" files, we simply specify a filter:

```{r}
qfiles = files() %>% 
	GenomicDataCommons::filter(type == "gene_expression")
# here is what the filter looks like after translation
str(get_filter(qfiles))
qfiles$filters$content
```

What if we want to create a filter based on e.g. the project 'TCGA-OVCA'? There are a few possible ways.

The first is based on R functionality with some intuition:

```{r}
grep(pattern = "pro", 
	 x = available_fields("files"), 
	 value = T) %>% 
	head()
```

Interestingly, project information is nested inside the case. We don't need to know that detail other than to know that we now have a few potential guesses for where our information might be in the files records. We need to know where because we need to construct the appropriate filter.

```{r}
# grep("project", available_fields("files"), value = T)

# see how many files are in each project
files() %>% 
	facet("cases.project.project_id") %>% 
	aggregations() %>% 
	head()
```

The `cases.projects.project_id` looks like it is a good fit. Also **note** that `TCGA-OV` is the correct `project_id`, not `TCGA-OVCA`. ***NOTE*** unlike dplyr, theh `filter()` function ***replaces*** the filter - it doesn't build on top of it.

```{r}
# add some filters
qfiles = files() %>% 
	GenomicDataCommons::filter(cases.project.project_id == "TCGA-OV" &
							   	type == "gene_expression")
# show the filters
str(get_filter(qfiles))
```

```{r}
# count how man files in the filtered object
qfiles %>% GenomicDataCommons::count()
```

Filters can be chained/nested. This is equivalent to the `&` filtering above:

```{r}
qfiles2 = files() %>% 
	filter(cases.project.project_id == "TCGA-OV") %>% 
	filter(type == "gene_expression")
qfiles2 %>% count()

(qfiles %>% count()) == (qfiles2 %>% count())
```

Generating a manifest for bulk downloads is as simple as asking for the manifest from the current query:

```{r}
manifest_df = qfiles %>% manifest()
head(manifest_df)
```

**Note** you might still not be there -- looking at filenames, there are suspiciously named files that might include "FPKM", "FPKM-UQ", or "counts". Another round of `grep()` and `available_fields()` looking for "type" turned up that the field "analysis.workflow_type" has the appropriate filter criteria.

```{r}
qfiles = files() %>% 
	filter(~ cases.project.project_id == "TCGA-OV" & 
		   	type == "gene_expression" & 
		   	analysis.workflow_type == "HTSeq - Counts")

manifest_df = qfiles %>% manifest()
nrow(manifest_df) # SAME as in GDC portal
```

The GDC Data Transfer Tool can be used (from R, `transfer()` or from the command line) to orchestrate high-performance, restartable transfers of all the files in the manifest. See the bulk downloads section for details.

## 4.2 Authentication

The GDC offers both “controlled-access” and “open” data. As of this writing, only data stored as files is “controlled-access”; that is, metadata accessible via the GDC is all “open” data and some files are “open” and some are “controlled-access”. Controlled-access data are only available after going through the process of obtaining access.

After controlled-access to one or more datasets has been granted, logging into the GDC web portal will allow you to access a GDC authentication token, which can be downloaded and then used to access available controlled-access data via the GenomicDataCommons package.

The GenomicDataCommons uses authentication tokens only for downloading data (see transfer and gdcdata documentation). The package includes a helper function, gdc_token, that looks for the token to be stored in one of three ways (resolved in this order):

1. As a string stored in the environment variable, GDC_TOKEN
2. As a file, stored in the file named by the environment variable, GDC_TOKEN_FILE
3. In a file in the user home directory, called .gdc_token

As a concrete example:

```{r}
token = gdc_token()
# transfer(..., token = token)
# # or
# transfer(..., token = get_token())
```

## 4.3 Datafile access and download

### 4.3.1 Data downloads via the GDC API

The `gdcdata()` function takes a character vector of one or more file ids. A simple way of producing such a vector is to produce a `manifest()` data frame and then pass in the first column, which will contain file ids.

```{r}
# get filenames
fnames = gdcdata(manifest_df$id[1:2])
fnames
```

Note that for controlled-access data, a GDC authentication token is required. Using the `BiocParallel` package may be useful for downloading in parallel, particularly for large numbers of smallish files.

### 4.3.2 Bulk downloads

The bulk download functionality is only efficient (as of v1.2.0 of the GDC Data Transfer Tool) for relatively large files, so use this approach only when transferring BAM files or larger VCF files, for example. Otherwise, consider using the approach shown above, perhaps in parallel.

```{r}
# FIXME: Error in gdc_client() : gdc_client not found
# fnames = gdcdata(manifest_df$id[3:10], access_method = "client")
```

### 4.3.3 BAM slicing

[TBA]

# 5 Use Cases

## 5.1 Cases

### 5.1.1 How many cases are there per project_id?

Find how many cases per project

```{r}
res = cases() %>% 
	facet("project.project_id") %>% 
	aggregations()
res
```

Plot the results

```{r}
ggplot(res$project.project_id, aes(x = factor(key, levels = key), y = doc_count)) + 
	geom_bar(stat = "identity") + 
	theme_light() + 
	theme(axis.text.x = element_text(angle = 90))
```

### 5.1.2 How many cases are included in all TARGET projects?

Get number of cases:

```{r}
cases() %>% 
	filter(~ project.program.name == "TARGET") %>% 
	count()
```

### 5.1.3 How many cases are included in all TCGA projects?

```{r}
cases() %>% 
	filter(~ project.program.name)
```

### 5.1.4 What is the breakdown of sample types in TCGA_BRCA?

```{r}
cases() %>% 
	filter(~ project.project_id == "TCGA-BRCA") %>% 
	facet("samples.sample_type") %>% 
	aggregations()
# OR
breakdown = cases() %>% 
	filter(~ project.project_id == "TCGA-BRCA") %>% 
	facet("samples.sample_type") %>% 
	aggregations()
breakdown$samples.sample_type
```

### 5.1.5 Fetch all samples in TCGA-BRCA that use "Solid Tissue" as a normal

```{r}
resp = cases() %>% 
	filter(~ project.project_id == "TCGA-BRCA" & 
		   	samples.sample_type == "solid tissue normal") %>% 
	select(c(default_fields("cases"), "samples.sample_type")) %>% 
	response_all()
count(resp)
```

View results from query

```{r}
res = resp %>% 
	results_all()
str(res["submitter_id"])
```

look at the IDs (UUIDs) of the samples in the object:

```{r}
ids(resp) %>% 
	head()
```

## 5.2 Files

### 5.2.1 How many of each type of file are available?

```{r}
res = files() %>% 
	facet("type") %>% 
	aggregations()
res$type
```

plot the results

```{r}
res_df = data.frame(res$type)
res_df$key = factor(res_df$key, levels = res_df$key)
	# OR
# ggplot(res_df, aes(x = factor(key, levels = key), y = doc_count)) + 
ggplot(res_df, aes(x = key, y = doc_count)) + 
	geom_bar(stat = "identity") + 
	theme_light() + 
	theme(axis.text.x = element_text(angle = 60, hjust = 1))
```

### 5.2.2 Find gene-level RNA-seq quantification files for GBM

```{r}
gbm_files = files() %>% 
	select(available_fields("files")) %>% 
	filter(~ cases.project.project_id == "TCGA-GBM" & 
		   	data_type == "Gene Expression Quantification" & 
		   	analysis.workflow_type == "HTSeq - Counts") %>% 
	select(c("file_id", "submitter_id")) %>%
	response()
gbm_files$results
```

from tut:

```{r}
q = files() %>%
    GenomicDataCommons::select(available_fields('files')) %>%
    filter(~ cases.project.project_id=='TCGA-GBM' &
               data_type=='Gene Expression Quantification')
q %>% facet('analysis.workflow_type') %>% aggregations()
```

```{r}
# so need to add another filter
file_ids = q %>% filter(~ cases.project.project_id=='TCGA-GBM' &
                            data_type=='Gene Expression Quantification' &
                            analysis.workflow_type == 'HTSeq - Counts') %>%
    GenomicDataCommons::select('file_id') %>%
    response_all() %>%
    ids()
file_ids
```

